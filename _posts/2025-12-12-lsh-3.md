---
title: "LSH-3"
date: 2025-12-12 16:56:20 +0900
description: "큰 집합에서 유사한 item을 찾는 방법을 알아보자"
categories: [Computer Science, Recommendation algorithm]
tags: [cs]
math: true
mermaid: true
---

## Distance Measures
일반화된 LSH는 점 사이의 "**거리**"에 기반합니다 (비슷한 점은 가깝다)
* d => distance measure는 다음의 조건을 만족해야합니다
<div style="border-left: 4px solid #63e6be; background-color: #1e1e1e; padding:10px;">
1. d(x,y) >=0<br>
2. d(x,y) = 0 iff x=y<br>
3. d(x,y) = d(y,x)<br>
4. d(x,y) <= d(x,z) + d(z,y) (triangle inequality)
</div>


* 유클리드 거리
  * L2 norm: 우리가 흔히 쓰는 거리
  * L1 norm: 각 차원에서 차이의 합
    * ex Maahattan disatnce
  ![](https://velog.velcdn.com/images/garage_keeper/post/1eeac507-1601-41d4-865b-a465fb092cab/image.png)

* 비유클리드 거리
  * jaccard distance = 1- jaccard similarity
  * cosine distance = angle between the vectors
  $d = \frac{p1 \cdot p2}{\vert p1\vert\vert p2\vert}$
  * edit distance = 2개의 문자열을 동일하게 만드는데 몇번의 삽입삭제가 필요한가
  $d = \vert x\vert + \vert y\vert -2\vert LCS(x,y)\vert\\
  LCS:\space Longest \space common \space susbsequence \space 
  $
  
## LSH Families of Hash Function
* 정의
<div style="border-left: 4px solid #63e6be; background-color: #1e1e1e; padding:10px;">
H hash 함수의 family 는 $(d_1,d_2,p_1,p_2)-sensitive$로 나타낼 수 있다.
이것의 의미는 집합$S$에서 모든 $x,y$에 대해서 다음을 의미한다.<br>
1. if $d(x,y) \le d_1$ 이면 $H$의 원소 $h$에 대해 $h(x)=h(y)$일 확률이 적어도 $p_1$이다.<br>
2. if $d(x,y) \ge d_2$ 이면 $H$의 원소 $h$에 대해 $h(x)=h(y)$일 확률이 많으면 $p_2$이다.
</div>
![](https://velog.velcdn.com/images/garage_keeper/post/04144cc8-00a9-4305-a5e4-689b04f181da/image.png)

* Example
  * $S$: subsets of some universal set, $d$: jaccard distance, $H$: minhash 함수의 집합
  [$h(x) = h(y)$] = $sim(x,y)$ = $1 - d(x,y)$ 
  * H is a $(\frac{1}{3},\frac{3}{4},\frac{2}{3},\frac{1}{4})$- sensitive family for S and d
 *LSH faimly in consine distance : [$h(x) = h(y)$]  = $1 - d(x,y)/180$ 

* LSH Family의 증폭
  * S-curve 함수의 효과를 위해
  * And (rows in band): $H' \space is \space (d_1,d_2,p_1^r,p_2^r)-sensitive$ (확률을 내리기때문에 d가 적은 구간에서 좋지 않음) 
  * Or (many band):$H' \space is \space (d_1,d_2,1-(1-p_1)^b,1-(1-p_2)^b)-sensitive$(확률을 올리기 때문에 d가 큰 구간에서 좋지 않음)
  * And - Or: $H' \space is \space (d_1,d_2,1-(1-p_1^r)^b,1-(1-p_2^r)^b)-sensitive$ 
  * Or-And: $H' \space is \space (d_1,d_2,(1-(1-p_1)^b)^r,(1-(1-p_2)^b))^r-sensitive$
  * 역시 적절한 b,r을 통해 적당한 threshold t를 찾아야한다.